{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/explored_reviews.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 2560 rows and 13 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length_text</th>\n",
       "      <th>review_length_title</th>\n",
       "      <th>polarity_text</th>\n",
       "      <th>polarity_title</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>subjectivity_title</th>\n",
       "      <th>sentiment_text</th>\n",
       "      <th>sentiment_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WORST AIRLINE</td>\n",
       "      <td>I travel a lot - and I travel often. Last week...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.512241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Terrible experience with Airfrance</td>\n",
       "      <td>This review is regarding flight AF185, we book...</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Extremely Disappointing Experience with Air Fr...</td>\n",
       "      <td>I recently flew with Air France on flight #185...</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>Negative</td>\n",
       "      <td>259</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.094163</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.488287</td>\n",
       "      <td>0.7</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Horrible</td>\n",
       "      <td>Wow!!! What a horrible experience!! I've alway...</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109373</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Worst Flight Experience I’ve Ever Had</td>\n",
       "      <td>I spent a fantastic 10-day vacation in Hong Ko...</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>Negative</td>\n",
       "      <td>311</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.126476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.485192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title  \\\n",
       "0       1                                      WORST AIRLINE   \n",
       "1       1                 Terrible experience with Airfrance   \n",
       "2       1  Extremely Disappointing Experience with Air Fr...   \n",
       "3       1                                           Horrible   \n",
       "4       1          The Worst Flight Experience I’ve Ever Had   \n",
       "\n",
       "                                                text publishedDate sentiment  \\\n",
       "0  I travel a lot - and I travel often. Last week...    2024-11-13  Negative   \n",
       "1  This review is regarding flight AF185, we book...    2024-11-13  Negative   \n",
       "2  I recently flew with Air France on flight #185...    2024-11-12  Negative   \n",
       "3  Wow!!! What a horrible experience!! I've alway...    2024-11-11  Negative   \n",
       "4  I spent a fantastic 10-day vacation in Hong Ko...    2024-11-11  Negative   \n",
       "\n",
       "   review_length_text  review_length_title  polarity_text  polarity_title  \\\n",
       "0                 408                    2       0.018448            -1.0   \n",
       "1                 157                    4      -0.060897            -1.0   \n",
       "2                 259                   11      -0.094163            -0.6   \n",
       "3                 274                    1      -0.109373            -1.0   \n",
       "4                 311                    7      -0.126476            -1.0   \n",
       "\n",
       "   subjectivity_text  subjectivity_title sentiment_text sentiment_title  \n",
       "0           0.512241                 1.0       positive        negative  \n",
       "1           0.592949                 1.0       negative        negative  \n",
       "2           0.488287                 0.7       negative        negative  \n",
       "3           0.494012                 1.0       negative        negative  \n",
       "4           0.485192                 1.0       negative        negative  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I travel a lot - and I travel often. Last week...</td>\n",
       "      <td>i travel a lot  and i travel often last week i...</td>\n",
       "      <td>WORST AIRLINE</td>\n",
       "      <td>worst airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This review is regarding flight AF185, we book...</td>\n",
       "      <td>this review is regarding flight af we booked a...</td>\n",
       "      <td>Terrible experience with Airfrance</td>\n",
       "      <td>terrible experience with airfrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I recently flew with Air France on flight #185...</td>\n",
       "      <td>i recently flew with air france on flight  fro...</td>\n",
       "      <td>Extremely Disappointing Experience with Air Fr...</td>\n",
       "      <td>extremely disappointing experience with air fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!!! What a horrible experience!! I've alway...</td>\n",
       "      <td>wow what a horrible experience ive always flow...</td>\n",
       "      <td>Horrible</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I spent a fantastic 10-day vacation in Hong Ko...</td>\n",
       "      <td>i spent a fantastic day vacation in hong kong ...</td>\n",
       "      <td>The Worst Flight Experience I’ve Ever Had</td>\n",
       "      <td>the worst flight experience ive ever had</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I travel a lot - and I travel often. Last week...   \n",
       "1  This review is regarding flight AF185, we book...   \n",
       "2  I recently flew with Air France on flight #185...   \n",
       "3  Wow!!! What a horrible experience!! I've alway...   \n",
       "4  I spent a fantastic 10-day vacation in Hong Ko...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  i travel a lot  and i travel often last week i...   \n",
       "1  this review is regarding flight af we booked a...   \n",
       "2  i recently flew with air france on flight  fro...   \n",
       "3  wow what a horrible experience ive always flow...   \n",
       "4  i spent a fantastic day vacation in hong kong ...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                      WORST AIRLINE   \n",
       "1                 Terrible experience with Airfrance   \n",
       "2  Extremely Disappointing Experience with Air Fr...   \n",
       "3                                           Horrible   \n",
       "4          The Worst Flight Experience I’ve Ever Had   \n",
       "\n",
       "                                         clean_title  \n",
       "0                                      worst airline  \n",
       "1                 terrible experience with airfrance  \n",
       "2  extremely disappointing experience with air fr...  \n",
       "3                                           horrible  \n",
       "4           the worst flight experience ive ever had  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean)\n",
    "df[\"clean_title\"] = df[\"title\"].apply(clean)\n",
    "\n",
    "df[[\"text\", \"clean_text\", \"title\", \"clean_title\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>tokens_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i travel a lot  and i travel often last week i...</td>\n",
       "      <td>[i, travel, a, lot, and, i, travel, often, las...</td>\n",
       "      <td>worst airline</td>\n",
       "      <td>[worst, airline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this review is regarding flight af we booked a...</td>\n",
       "      <td>[this, review, is, regarding, flight, af, we, ...</td>\n",
       "      <td>terrible experience with airfrance</td>\n",
       "      <td>[terrible, experience, with, airfrance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i recently flew with air france on flight  fro...</td>\n",
       "      <td>[i, recently, flew, with, air, france, on, fli...</td>\n",
       "      <td>extremely disappointing experience with air fr...</td>\n",
       "      <td>[extremely, disappointing, experience, with, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow what a horrible experience ive always flow...</td>\n",
       "      <td>[wow, what, a, horrible, experience, ive, alwa...</td>\n",
       "      <td>horrible</td>\n",
       "      <td>[horrible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i spent a fantastic day vacation in hong kong ...</td>\n",
       "      <td>[i, spent, a, fantastic, day, vacation, in, ho...</td>\n",
       "      <td>the worst flight experience ive ever had</td>\n",
       "      <td>[the, worst, flight, experience, ive, ever, had]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  i travel a lot  and i travel often last week i...   \n",
       "1  this review is regarding flight af we booked a...   \n",
       "2  i recently flew with air france on flight  fro...   \n",
       "3  wow what a horrible experience ive always flow...   \n",
       "4  i spent a fantastic day vacation in hong kong ...   \n",
       "\n",
       "                                         tokens_text  \\\n",
       "0  [i, travel, a, lot, and, i, travel, often, las...   \n",
       "1  [this, review, is, regarding, flight, af, we, ...   \n",
       "2  [i, recently, flew, with, air, france, on, fli...   \n",
       "3  [wow, what, a, horrible, experience, ive, alwa...   \n",
       "4  [i, spent, a, fantastic, day, vacation, in, ho...   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0                                      worst airline   \n",
       "1                 terrible experience with airfrance   \n",
       "2  extremely disappointing experience with air fr...   \n",
       "3                                           horrible   \n",
       "4           the worst flight experience ive ever had   \n",
       "\n",
       "                                        tokens_title  \n",
       "0                                   [worst, airline]  \n",
       "1            [terrible, experience, with, airfrance]  \n",
       "2  [extremely, disappointing, experience, with, a...  \n",
       "3                                         [horrible]  \n",
       "4   [the, worst, flight, experience, ive, ever, had]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "df[\"tokens_text\"] = df[\"clean_text\"].apply(tokenize)\n",
    "df[\"tokens_title\"] = df[\"clean_title\"].apply(tokenize)\n",
    "\n",
    "df[[\"clean_text\", \"tokens_text\", \"clean_title\", \"tokens_title\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>tokens_text_nostop</th>\n",
       "      <th>tokens_title</th>\n",
       "      <th>tokens_title_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, travel, a, lot, and, i, travel, often, las...</td>\n",
       "      <td>[travel, lot, travel, often, last, week, flew,...</td>\n",
       "      <td>[worst, airline]</td>\n",
       "      <td>[worst, airline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, review, is, regarding, flight, af, we, ...</td>\n",
       "      <td>[review, regarding, flight, af, booked, econom...</td>\n",
       "      <td>[terrible, experience, with, airfrance]</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, recently, flew, with, air, france, on, fli...</td>\n",
       "      <td>[recently, flew, air, france, flight, hong, ko...</td>\n",
       "      <td>[extremely, disappointing, experience, with, a...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[wow, what, a, horrible, experience, ive, alwa...</td>\n",
       "      <td>[wow, horrible, experience, ive, always, flown...</td>\n",
       "      <td>[horrible]</td>\n",
       "      <td>[horrible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, spent, a, fantastic, day, vacation, in, ho...</td>\n",
       "      <td>[spent, fantastic, day, vacation, hong, kong, ...</td>\n",
       "      <td>[the, worst, flight, experience, ive, ever, had]</td>\n",
       "      <td>[worst, flight, experience, ive, ever]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tokens_text  \\\n",
       "0  [i, travel, a, lot, and, i, travel, often, las...   \n",
       "1  [this, review, is, regarding, flight, af, we, ...   \n",
       "2  [i, recently, flew, with, air, france, on, fli...   \n",
       "3  [wow, what, a, horrible, experience, ive, alwa...   \n",
       "4  [i, spent, a, fantastic, day, vacation, in, ho...   \n",
       "\n",
       "                                  tokens_text_nostop  \\\n",
       "0  [travel, lot, travel, often, last, week, flew,...   \n",
       "1  [review, regarding, flight, af, booked, econom...   \n",
       "2  [recently, flew, air, france, flight, hong, ko...   \n",
       "3  [wow, horrible, experience, ive, always, flown...   \n",
       "4  [spent, fantastic, day, vacation, hong, kong, ...   \n",
       "\n",
       "                                        tokens_title  \\\n",
       "0                                   [worst, airline]   \n",
       "1            [terrible, experience, with, airfrance]   \n",
       "2  [extremely, disappointing, experience, with, a...   \n",
       "3                                         [horrible]   \n",
       "4   [the, worst, flight, experience, ive, ever, had]   \n",
       "\n",
       "                                 tokens_title_nostop  \n",
       "0                                   [worst, airline]  \n",
       "1                  [terrible, experience, airfrance]  \n",
       "2  [extremely, disappointing, experience, air, fr...  \n",
       "3                                         [horrible]  \n",
       "4             [worst, flight, experience, ive, ever]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "df[\"tokens_text_nostop\"] = df[\"tokens_text\"].apply(remove_stopwords)\n",
    "df[\"tokens_title_nostop\"] = df[\"tokens_title\"].apply(remove_stopwords)\n",
    "\n",
    "df[[\"tokens_text\", \"tokens_text_nostop\", \"tokens_title\", \"tokens_title_nostop\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_text_nostop</th>\n",
       "      <th>stemmed_text_porter</th>\n",
       "      <th>stemmed_text_snowball</th>\n",
       "      <th>tokens_title_nostop</th>\n",
       "      <th>stemmed_title_porter</th>\n",
       "      <th>stemmed_title_snowball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[travel, lot, travel, often, last, week, flew,...</td>\n",
       "      <td>[travel, lot, travel, often, last, week, flew,...</td>\n",
       "      <td>[travel, lot, travel, often, last, week, flew,...</td>\n",
       "      <td>[worst, airline]</td>\n",
       "      <td>[worst, airlin]</td>\n",
       "      <td>[worst, airlin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[review, regarding, flight, af, booked, econom...</td>\n",
       "      <td>[review, regard, flight, af, book, economi, fl...</td>\n",
       "      <td>[review, regard, flight, af, book, economi, fl...</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "      <td>[terribl, experi, airfranc]</td>\n",
       "      <td>[terribl, experi, airfranc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recently, flew, air, france, flight, hong, ko...</td>\n",
       "      <td>[recent, flew, air, franc, flight, hong, kong,...</td>\n",
       "      <td>[recent, flew, air, franc, flight, hong, kong,...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "      <td>[extrem, disappoint, experi, air, franc, fligh...</td>\n",
       "      <td>[extrem, disappoint, experi, air, franc, fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[wow, horrible, experience, ive, always, flown...</td>\n",
       "      <td>[wow, horribl, experi, ive, alway, flown, port...</td>\n",
       "      <td>[wow, horribl, experi, ive, alway, flown, port...</td>\n",
       "      <td>[horrible]</td>\n",
       "      <td>[horribl]</td>\n",
       "      <td>[horribl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[spent, fantastic, day, vacation, hong, kong, ...</td>\n",
       "      <td>[spent, fantast, day, vacat, hong, kong, famil...</td>\n",
       "      <td>[spent, fantast, day, vacat, hong, kong, famil...</td>\n",
       "      <td>[worst, flight, experience, ive, ever]</td>\n",
       "      <td>[worst, flight, experi, ive, ever]</td>\n",
       "      <td>[worst, flight, experi, ive, ever]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tokens_text_nostop  \\\n",
       "0  [travel, lot, travel, often, last, week, flew,...   \n",
       "1  [review, regarding, flight, af, booked, econom...   \n",
       "2  [recently, flew, air, france, flight, hong, ko...   \n",
       "3  [wow, horrible, experience, ive, always, flown...   \n",
       "4  [spent, fantastic, day, vacation, hong, kong, ...   \n",
       "\n",
       "                                 stemmed_text_porter  \\\n",
       "0  [travel, lot, travel, often, last, week, flew,...   \n",
       "1  [review, regard, flight, af, book, economi, fl...   \n",
       "2  [recent, flew, air, franc, flight, hong, kong,...   \n",
       "3  [wow, horribl, experi, ive, alway, flown, port...   \n",
       "4  [spent, fantast, day, vacat, hong, kong, famil...   \n",
       "\n",
       "                               stemmed_text_snowball  \\\n",
       "0  [travel, lot, travel, often, last, week, flew,...   \n",
       "1  [review, regard, flight, af, book, economi, fl...   \n",
       "2  [recent, flew, air, franc, flight, hong, kong,...   \n",
       "3  [wow, horribl, experi, ive, alway, flown, port...   \n",
       "4  [spent, fantast, day, vacat, hong, kong, famil...   \n",
       "\n",
       "                                 tokens_title_nostop  \\\n",
       "0                                   [worst, airline]   \n",
       "1                  [terrible, experience, airfrance]   \n",
       "2  [extremely, disappointing, experience, air, fr...   \n",
       "3                                         [horrible]   \n",
       "4             [worst, flight, experience, ive, ever]   \n",
       "\n",
       "                                stemmed_title_porter  \\\n",
       "0                                    [worst, airlin]   \n",
       "1                        [terribl, experi, airfranc]   \n",
       "2  [extrem, disappoint, experi, air, franc, fligh...   \n",
       "3                                          [horribl]   \n",
       "4                 [worst, flight, experi, ive, ever]   \n",
       "\n",
       "                              stemmed_title_snowball  \n",
       "0                                    [worst, airlin]  \n",
       "1                        [terribl, experi, airfranc]  \n",
       "2  [extrem, disappoint, experi, air, franc, fligh...  \n",
       "3                                          [horribl]  \n",
       "4                 [worst, flight, experi, ive, ever]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "\n",
    "df[\"stemmed_text_porter\"] = df[\"tokens_text_nostop\"].apply(\n",
    "    lambda x: stem_tokens(x, porter_stemmer)\n",
    ")\n",
    "df[\"stemmed_title_porter\"] = df[\"tokens_title_nostop\"].apply(\n",
    "    lambda x: stem_tokens(x, porter_stemmer)\n",
    ")\n",
    "\n",
    "df[\"stemmed_text_snowball\"] = df[\"tokens_text_nostop\"].apply(\n",
    "    lambda x: stem_tokens(x, snowball_stemmer)\n",
    ")\n",
    "df[\"stemmed_title_snowball\"] = df[\"tokens_title_nostop\"].apply(\n",
    "    lambda x: stem_tokens(x, snowball_stemmer)\n",
    ")\n",
    "\n",
    "df[\n",
    "    [\n",
    "        \"tokens_text_nostop\",\n",
    "        \"stemmed_text_porter\",\n",
    "        \"stemmed_text_snowball\",\n",
    "        \"tokens_title_nostop\",\n",
    "        \"stemmed_title_porter\",\n",
    "        \"stemmed_title_snowball\",\n",
    "    ]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_text_nostop</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>tokens_title_nostop</th>\n",
       "      <th>lemmatized_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[travel, lot, travel, often, last, week, flew,...</td>\n",
       "      <td>[travel, lot, travel, often, last, week, fly, ...</td>\n",
       "      <td>[worst, airline]</td>\n",
       "      <td>[bad, airline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[review, regarding, flight, af, booked, econom...</td>\n",
       "      <td>[review, regard, flight, af, book, economy, fl...</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recently, flew, air, france, flight, hong, ko...</td>\n",
       "      <td>[recently, fly, air, france, flight, hong, kon...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[wow, horrible, experience, ive, always, flown...</td>\n",
       "      <td>[wow, horrible, experience, I, ve, always, fly...</td>\n",
       "      <td>[horrible]</td>\n",
       "      <td>[horrible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[spent, fantastic, day, vacation, hong, kong, ...</td>\n",
       "      <td>[spend, fantastic, day, vacation, hong, kong, ...</td>\n",
       "      <td>[worst, flight, experience, ive, ever]</td>\n",
       "      <td>[bad, flight, experience, I, ve, ever]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tokens_text_nostop  \\\n",
       "0  [travel, lot, travel, often, last, week, flew,...   \n",
       "1  [review, regarding, flight, af, booked, econom...   \n",
       "2  [recently, flew, air, france, flight, hong, ko...   \n",
       "3  [wow, horrible, experience, ive, always, flown...   \n",
       "4  [spent, fantastic, day, vacation, hong, kong, ...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  [travel, lot, travel, often, last, week, fly, ...   \n",
       "1  [review, regard, flight, af, book, economy, fl...   \n",
       "2  [recently, fly, air, france, flight, hong, kon...   \n",
       "3  [wow, horrible, experience, I, ve, always, fly...   \n",
       "4  [spend, fantastic, day, vacation, hong, kong, ...   \n",
       "\n",
       "                                 tokens_title_nostop  \\\n",
       "0                                   [worst, airline]   \n",
       "1                  [terrible, experience, airfrance]   \n",
       "2  [extremely, disappointing, experience, air, fr...   \n",
       "3                                         [horrible]   \n",
       "4             [worst, flight, experience, ive, ever]   \n",
       "\n",
       "                                    lemmatized_title  \n",
       "0                                     [bad, airline]  \n",
       "1                  [terrible, experience, airfrance]  \n",
       "2  [extremely, disappointing, experience, air, fr...  \n",
       "3                                         [horrible]  \n",
       "4             [bad, flight, experience, I, ve, ever]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def lemmatize_tokens(text):\n",
    "    doc = nlp(\" \".join(text))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "\n",
    "df[\"lemmatized_text\"] = df[\"tokens_text_nostop\"].apply(lemmatize_tokens)\n",
    "df[\"lemmatized_title\"] = df[\"tokens_title_nostop\"].apply(lemmatize_tokens)\n",
    "\n",
    "df[\n",
    "    [\"tokens_text_nostop\", \"lemmatized_text\", \"tokens_title_nostop\", \"lemmatized_title\"]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"publishedDate\"] = pd.to_datetime(df[\"publishedDate\"], errors=\"coerce\")\n",
    "\n",
    "df[\"day_of_week\"] = df[\"publishedDate\"].dt.day_name()\n",
    "df[\"month\"] = df[\"publishedDate\"].dt.month\n",
    "df[\"year\"] = df[\"publishedDate\"].dt.year\n",
    "\n",
    "df.drop(columns=[\"publishedDate\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_length_text</th>\n",
       "      <th>review_length_title</th>\n",
       "      <th>polarity_text</th>\n",
       "      <th>polarity_title</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>subjectivity_title</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.512241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[travel, lot, travel, often, last, week, fly, ...</td>\n",
       "      <td>[bad, airline]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[review, regard, flight, af, book, economy, fl...</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.094163</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.488287</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[recently, fly, air, france, flight, hong, kon...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109373</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[wow, horrible, experience, I, ve, always, fly...</td>\n",
       "      <td>[horrible]</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.126476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.485192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[spend, fantastic, day, vacation, hong, kong, ...</td>\n",
       "      <td>[bad, flight, experience, I, ve, ever]</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  review_length_text  review_length_title  polarity_text  \\\n",
       "0       1                 408                    2       0.018448   \n",
       "1       1                 157                    4      -0.060897   \n",
       "2       1                 259                   11      -0.094163   \n",
       "3       1                 274                    1      -0.109373   \n",
       "4       1                 311                    7      -0.126476   \n",
       "\n",
       "   polarity_title  subjectivity_text  subjectivity_title  \\\n",
       "0            -1.0           0.512241                 1.0   \n",
       "1            -1.0           0.592949                 1.0   \n",
       "2            -0.6           0.488287                 0.7   \n",
       "3            -1.0           0.494012                 1.0   \n",
       "4            -1.0           0.485192                 1.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  [travel, lot, travel, often, last, week, fly, ...   \n",
       "1  [review, regard, flight, af, book, economy, fl...   \n",
       "2  [recently, fly, air, france, flight, hong, kon...   \n",
       "3  [wow, horrible, experience, I, ve, always, fly...   \n",
       "4  [spend, fantastic, day, vacation, hong, kong, ...   \n",
       "\n",
       "                                    lemmatized_title day_of_week  month  year  \n",
       "0                                     [bad, airline]   Wednesday     11  2024  \n",
       "1                  [terrible, experience, airfrance]   Wednesday     11  2024  \n",
       "2  [extremely, disappointing, experience, air, fr...     Tuesday     11  2024  \n",
       "3                                         [horrible]      Monday     11  2024  \n",
       "4             [bad, flight, experience, I, ve, ever]      Monday     11  2024  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_columns = [\n",
    "    \"rating\",  # Numerical sentiment score\n",
    "    \"review_length_text\",\n",
    "    \"review_length_title\",  # Text length analysis\n",
    "    \"polarity_text\",\n",
    "    \"polarity_title\",  # Sentiment polarity scores\n",
    "    \"subjectivity_text\",\n",
    "    \"subjectivity_title\",  # Opinion-based scores\n",
    "    \"lemmatized_text\",\n",
    "    \"lemmatized_title\",  # Clean processed text for vectorization\n",
    "    \"day_of_week\",\n",
    "    \"month\",\n",
    "    \"year\",  # Time-based trend analysis\n",
    "]\n",
    "\n",
    "df_final = df[final_columns]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4374/2120309351.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final[\"lemmatized_text\"] = remove_custom_stopwords(\n"
     ]
    }
   ],
   "source": [
    "# Define a refined custom stopword list\n",
    "custom_stopwords = set(\n",
    "    [\n",
    "        # Domain-Specific (Removing high-frequency airline words that dilute topics)\n",
    "        \"flight\",\n",
    "        \"flights\",\n",
    "        \"air\",\n",
    "        \"france\",\n",
    "        \"af\",\n",
    "        \"airfrance\",\n",
    "        \"airline\",\n",
    "        \"airlines\",\n",
    "        \"plane\",\n",
    "        \"aircraft\",\n",
    "        \"aircrafts\",\n",
    "        \"airplanes\",\n",
    "        \"airplane\",\n",
    "        \"airport\",\n",
    "        \"airports\",\n",
    "        \"departure\",\n",
    "        \"arrival\",\n",
    "        \"terminal\",\n",
    "        \"gate\",\n",
    "        \"connection\",\n",
    "        \"layover\",\n",
    "        \"transit\",\n",
    "        \"check\",\n",
    "        \"boarding\",\n",
    "        \"security\",\n",
    "        \"passport\",\n",
    "        \"customs\",\n",
    "        \"crew\",\n",
    "        \"attendant\",\n",
    "        \"passenger\",\n",
    "        \"passengers\",\n",
    "        \"service\",\n",
    "        \"staff\",\n",
    "        \"paris\",\n",
    "        \"well\",\n",
    "        # Keeping topic-relevant words:\n",
    "        # ✅ \"baggage\" (lost baggage could be a topic)\n",
    "        # ✅ \"business\", \"economy\", \"premium\" (could be topic-relevant)\n",
    "        # ✅ \"delay\", \"cancel\", \"reschedule\" (important for service complaints)\n",
    "        # ✅ \"meal\", \"food\", \"drink\" (potential topic)\n",
    "        # ❌ Removing \"seat\", \"class\", \"window\", \"row\" (appear across all topics)\n",
    "        # Common Verbs (Removing generic action words)\n",
    "        \"get\",\n",
    "        \"go\",\n",
    "        \"come\",\n",
    "        \"take\",\n",
    "        \"make\",\n",
    "        \"find\",\n",
    "        \"give\",\n",
    "        \"put\",\n",
    "        \"see\",\n",
    "        \"know\",\n",
    "        \"want\",\n",
    "        \"would\",\n",
    "        \"could\",\n",
    "        \"should\",\n",
    "        \"must\",\n",
    "        \"did\",\n",
    "        \"does\",\n",
    "        \"do\",\n",
    "        \"say\",\n",
    "        \"let\",\n",
    "        \"tell\",\n",
    "        \"call\",\n",
    "        \"ask\",\n",
    "        \"try\",\n",
    "        \"need\",\n",
    "        \"think\",\n",
    "        \"use\",\n",
    "        \"work\",\n",
    "        \"wait\",\n",
    "        \"expect\",\n",
    "        \"offer\",\n",
    "        \"look\",\n",
    "        \"pay\",\n",
    "        \"charge\",\n",
    "        \"buy\",\n",
    "        \"book\",\n",
    "        # Auxiliary Words & Negations (Common filler words)\n",
    "        \"not\",\n",
    "        \"never\",\n",
    "        \"always\",\n",
    "        \"still\",\n",
    "        \"even\",\n",
    "        \"much\",\n",
    "        \"very\",\n",
    "        \"more\",\n",
    "        \"less\",\n",
    "        \"like\",\n",
    "        \"without\",\n",
    "        \"thing\",\n",
    "        \"another\",\n",
    "        \"many\",\n",
    "        \"every\",\n",
    "        \"way\",\n",
    "        \"back\",\n",
    "        \"time\",\n",
    "        \"now\",\n",
    "        \"soon\",\n",
    "        \"later\",\n",
    "        \"then\",\n",
    "        \"before\",\n",
    "        \"after\",\n",
    "        \"ago\",\n",
    "        \"today\",\n",
    "        \"yesterday\",\n",
    "        \"tomorrow\",\n",
    "        \"early\",\n",
    "        \"late\",\n",
    "        \"long\",\n",
    "        \"short\",\n",
    "        \"already\",\n",
    "        \"yet\",\n",
    "        \"just\",\n",
    "        # Pronouns & Function Words (Non-informative words)\n",
    "        \"i\",\n",
    "        \"me\",\n",
    "        \"my\",\n",
    "        \"mine\",\n",
    "        \"you\",\n",
    "        \"your\",\n",
    "        \"yours\",\n",
    "        \"we\",\n",
    "        \"our\",\n",
    "        \"ours\",\n",
    "        \"they\",\n",
    "        \"them\",\n",
    "        \"their\",\n",
    "        \"theirs\",\n",
    "        \"he\",\n",
    "        \"him\",\n",
    "        \"his\",\n",
    "        \"she\",\n",
    "        \"her\",\n",
    "        \"hers\",\n",
    "        \"it\",\n",
    "        \"its\",\n",
    "        \"this\",\n",
    "        \"that\",\n",
    "        \"these\",\n",
    "        \"those\",\n",
    "        \"who\",\n",
    "        \"whom\",\n",
    "        \"whose\",\n",
    "        \"which\",\n",
    "        \"what\",\n",
    "        \"where\",\n",
    "        \"when\",\n",
    "        \"why\",\n",
    "        \"how\",\n",
    "        \"there\",\n",
    "        \"here\",\n",
    "        \"some\",\n",
    "        \"any\",\n",
    "        \"few\",\n",
    "        \"several\",\n",
    "        \"many\",\n",
    "        \"others\",\n",
    "        # Adjectives & Opinion Words (Subjective words that don’t define topics well)\n",
    "        \"good\",\n",
    "        \"bad\",\n",
    "        \"best\",\n",
    "        \"worst\",\n",
    "        \"nice\",\n",
    "        \"great\",\n",
    "        \"terrible\",\n",
    "        \"awful\",\n",
    "        \"horrible\",\n",
    "        \"amazing\",\n",
    "        \"fantastic\",\n",
    "        \"excellent\",\n",
    "        \"perfect\",\n",
    "        \"fine\",\n",
    "        \"poor\",\n",
    "        \"better\",\n",
    "        \"worse\",\n",
    "        \"new\",\n",
    "        \"old\",\n",
    "        \"big\",\n",
    "        \"small\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"fast\",\n",
    "        \"slow\",\n",
    "        \"easy\",\n",
    "        \"hard\",\n",
    "        # Other Commonly Overused Words\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"three\",\n",
    "        \"four\",\n",
    "        \"five\",\n",
    "        \"six\",\n",
    "        \"seven\",\n",
    "        \"eight\",\n",
    "        \"nine\",\n",
    "        \"ten\",\n",
    "        \"hundred\",\n",
    "        \"thousand\",\n",
    "        \"million\",\n",
    "        \"someone\",\n",
    "        \"everyone\",\n",
    "        \"thing\",\n",
    "        \"something\",\n",
    "        \"everything\",\n",
    "        \"nothing\",\n",
    "        \"yes\",\n",
    "        \"no\",\n",
    "        \"ok\",\n",
    "        \"okay\",\n",
    "        \"probably\",\n",
    "        \"definitely\",\n",
    "        \"bit\",\n",
    "        \"lot\",\n",
    "        \"kind\",\n",
    "        \"sort\",\n",
    "        \"part\",\n",
    "        \"piece\",\n",
    "        \"level\",\n",
    "        \"place\",\n",
    "        \"point\",\n",
    "        \"case\",\n",
    "        \"situation\",\n",
    "        \"matter\",\n",
    "        \"reason\",\n",
    "        \"result\",\n",
    "        \"problem\",\n",
    "        \"solution\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def remove_custom_stopwords(text_list, stopwords):\n",
    "    \"\"\"Remove custom stopwords from tokenized text\"\"\"\n",
    "    return [[word for word in text if word not in stopwords] for text in text_list]\n",
    "\n",
    "\n",
    "# Apply stopword removal to lemmatized text\n",
    "df_final[\"lemmatized_text\"] = remove_custom_stopwords(\n",
    "    df_final[\"lemmatized_text\"], custom_stopwords\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved processed dataset at: /home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/processed/processed_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "final_path = \"/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/processed/processed_reviews.csv\"\n",
    "df_final.to_csv(final_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Successfully saved processed dataset at: {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_length_text</th>\n",
       "      <th>review_length_title</th>\n",
       "      <th>polarity_text</th>\n",
       "      <th>polarity_title</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>subjectivity_title</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.512241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[travel, travel, often, last, week, fly, texas...</td>\n",
       "      <td>[bad, airline]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[review, regard, economy, flex, choose, seat, ...</td>\n",
       "      <td>[terrible, experience, airfrance]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.094163</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.488287</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[recently, fly, hong, kong, nov, th, deeply, d...</td>\n",
       "      <td>[extremely, disappointing, experience, air, fr...</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109373</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[wow, experience, I, ve, fly, porter, shock, c...</td>\n",
       "      <td>[horrible]</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.126476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.485192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[spend, day, vacation, hong, kong, family, ret...</td>\n",
       "      <td>[bad, flight, experience, I, ve, ever]</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  review_length_text  review_length_title  polarity_text  \\\n",
       "0       1                 408                    2       0.018448   \n",
       "1       1                 157                    4      -0.060897   \n",
       "2       1                 259                   11      -0.094163   \n",
       "3       1                 274                    1      -0.109373   \n",
       "4       1                 311                    7      -0.126476   \n",
       "\n",
       "   polarity_title  subjectivity_text  subjectivity_title  \\\n",
       "0            -1.0           0.512241                 1.0   \n",
       "1            -1.0           0.592949                 1.0   \n",
       "2            -0.6           0.488287                 0.7   \n",
       "3            -1.0           0.494012                 1.0   \n",
       "4            -1.0           0.485192                 1.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  [travel, travel, often, last, week, fly, texas...   \n",
       "1  [review, regard, economy, flex, choose, seat, ...   \n",
       "2  [recently, fly, hong, kong, nov, th, deeply, d...   \n",
       "3  [wow, experience, I, ve, fly, porter, shock, c...   \n",
       "4  [spend, day, vacation, hong, kong, family, ret...   \n",
       "\n",
       "                                    lemmatized_title day_of_week  month  year  \n",
       "0                                     [bad, airline]   Wednesday     11  2024  \n",
       "1                  [terrible, experience, airfrance]   Wednesday     11  2024  \n",
       "2  [extremely, disappointing, experience, air, fr...     Tuesday     11  2024  \n",
       "3                                         [horrible]      Monday     11  2024  \n",
       "4             [bad, flight, experience, I, ve, ever]      Monday     11  2024  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_airfrance_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
