{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/processed/processed_reviews.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_length_text</th>\n",
       "      <th>review_length_title</th>\n",
       "      <th>polarity_text</th>\n",
       "      <th>polarity_title</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>subjectivity_title</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.512241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['travel', 'lot', 'travel', 'often', 'last', '...</td>\n",
       "      <td>['bad', 'airline']</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['review', 'regard', 'flight', 'af', 'book', '...</td>\n",
       "      <td>['terrible', 'experience', 'airfrance']</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.094163</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.488287</td>\n",
       "      <td>0.7</td>\n",
       "      <td>['recently', 'fly', 'air', 'france', 'flight',...</td>\n",
       "      <td>['extremely', 'disappointing', 'experience', '...</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109373</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['wow', 'horrible', 'experience', 'I', 've', '...</td>\n",
       "      <td>['horrible']</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>311</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.126476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.485192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['spend', 'fantastic', 'day', 'vacation', 'hon...</td>\n",
       "      <td>['bad', 'flight', 'experience', 'I', 've', 'ev...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  review_length_text  review_length_title  polarity_text  \\\n",
       "0       1                 408                    2       0.018448   \n",
       "1       1                 157                    4      -0.060897   \n",
       "2       1                 259                   11      -0.094163   \n",
       "3       1                 274                    1      -0.109373   \n",
       "4       1                 311                    7      -0.126476   \n",
       "\n",
       "   polarity_title  subjectivity_text  subjectivity_title  \\\n",
       "0            -1.0           0.512241                 1.0   \n",
       "1            -1.0           0.592949                 1.0   \n",
       "2            -0.6           0.488287                 0.7   \n",
       "3            -1.0           0.494012                 1.0   \n",
       "4            -1.0           0.485192                 1.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  ['travel', 'lot', 'travel', 'often', 'last', '...   \n",
       "1  ['review', 'regard', 'flight', 'af', 'book', '...   \n",
       "2  ['recently', 'fly', 'air', 'france', 'flight',...   \n",
       "3  ['wow', 'horrible', 'experience', 'I', 've', '...   \n",
       "4  ['spend', 'fantastic', 'day', 'vacation', 'hon...   \n",
       "\n",
       "                                    lemmatized_title day_of_week  month  year  \n",
       "0                                 ['bad', 'airline']   Wednesday     11  2024  \n",
       "1            ['terrible', 'experience', 'airfrance']   Wednesday     11  2024  \n",
       "2  ['extremely', 'disappointing', 'experience', '...     Tuesday     11  2024  \n",
       "3                                       ['horrible']      Monday     11  2024  \n",
       "4  ['bad', 'flight', 'experience', 'I', 've', 'ev...      Monday     11  2024  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ac</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yr</th>\n",
       "      <th>yvr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  aboard  absolute  absolutely  ac  accent  accept  \\\n",
       "0        0     0       0         0           0   0       0       0   \n",
       "1        0     0       0         0           0   0       0       0   \n",
       "2        0     0       0         0           0   0       0       0   \n",
       "3        0     0       0         0           0   0       0       0   \n",
       "4        0     0       0         0           0   0       0       1   \n",
       "\n",
       "   acceptable  access  ...  yes  yesterday  yogurt  york  young  yr  yvr  \\\n",
       "0           0       0  ...    0          0       0     0      0   0    0   \n",
       "1           0       0  ...    0          0       0     0      0   0    0   \n",
       "2           0       0  ...    0          0       0     0      0   0    0   \n",
       "3           0       0  ...    0          0       0     0      0   0    0   \n",
       "4           0       0  ...    0          0       0     0      0   0    0   \n",
       "\n",
       "   zero  zone  zurich  \n",
       "0     0     0       0  \n",
       "1     0     0       0  \n",
       "2     0     0       0  \n",
       "3     0     0       0  \n",
       "4     0     0       0  \n",
       "\n",
       "[5 rows x 2193 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(max_features=10000, min_df=5, stop_words=\"english\")\n",
    "X_bow = bow_vectorizer.fit_transform(df[\"lemmatized_text\"].astype(str))\n",
    "\n",
    "df_bow = pd.DataFrame(X_bow.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "\n",
    "with open('/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/bow_vectorized.pkl', 'wb') as f:\n",
    "    pickle.dump(df_bow, f)\n",
    "\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able check</th>\n",
       "      <th>able fly</th>\n",
       "      <th>able sleep</th>\n",
       "      <th>able stretch</th>\n",
       "      <th>aboard</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>ac</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yr</th>\n",
       "      <th>yr old</th>\n",
       "      <th>yvr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  able check  able fly  able sleep  able stretch  aboard  \\\n",
       "0      0.0   0.0         0.0       0.0         0.0           0.0     0.0   \n",
       "1      0.0   0.0         0.0       0.0         0.0           0.0     0.0   \n",
       "2      0.0   0.0         0.0       0.0         0.0           0.0     0.0   \n",
       "3      0.0   0.0         0.0       0.0         0.0           0.0     0.0   \n",
       "4      0.0   0.0         0.0       0.0         0.0           0.0     0.0   \n",
       "\n",
       "   absolute  absolutely   ac  ...  yesterday  yogurt  york  young   yr  \\\n",
       "0       0.0         0.0  0.0  ...        0.0     0.0   0.0    0.0  0.0   \n",
       "1       0.0         0.0  0.0  ...        0.0     0.0   0.0    0.0  0.0   \n",
       "2       0.0         0.0  0.0  ...        0.0     0.0   0.0    0.0  0.0   \n",
       "3       0.0         0.0  0.0  ...        0.0     0.0   0.0    0.0  0.0   \n",
       "4       0.0         0.0  0.0  ...        0.0     0.0   0.0    0.0  0.0   \n",
       "\n",
       "   yr old  yvr  zero  zone  zurich  \n",
       "0     0.0  0.0   0.0   0.0     0.0  \n",
       "1     0.0  0.0   0.0   0.0     0.0  \n",
       "2     0.0  0.0   0.0   0.0     0.0  \n",
       "3     0.0  0.0   0.0   0.0     0.0  \n",
       "4     0.0  0.0   0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 4455 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000, \n",
    "    stop_words=\"english\", \n",
    "    ngram_range=(1,2), \n",
    "    min_df=5, \n",
    ")\n",
    "\n",
    "# Fit and transform lemmatized text\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['lemmatized_text'].astype(str))\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Save TF-IDF matrix\n",
    "with open('/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/tfidf_vectorized.pkl', 'wb') as f:\n",
    "    pickle.dump(df_tfidf, f)\n",
    "\n",
    "\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec embeddings successfully saved to /home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/word2vec_vectorized.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2vec_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.26565692, 0.15300937, 0.023394726, -0.0995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.14890291, 0.28530204, 0.0012725089, -0.055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.1506756, 0.27368864, 0.015880648, 0.044413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.1706126, 0.2824239, 0.013168015, -0.061199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.17064783, 0.16075645, 0.0037159673, -0.000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  word2vec_embedding\n",
       "0  [-0.26565692, 0.15300937, 0.023394726, -0.0995...\n",
       "1  [-0.14890291, 0.28530204, 0.0012725089, -0.055...\n",
       "2  [-0.1506756, 0.27368864, 0.015880648, 0.044413...\n",
       "3  [-0.1706126, 0.2824239, 0.013168015, -0.061199...\n",
       "4  [-0.17064783, 0.16075645, 0.0037159673, -0.000..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews = [text.split() for text in df[\"lemmatized_text\"].astype(str)]\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_reviews,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "def get_word2vec_embeddings(text):\n",
    "    words = text.split()\n",
    "    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "df['word2vec_embedding'] = df['lemmatized_text'].apply(get_word2vec_embeddings)\n",
    "\n",
    "# Convert embeddings to a list (needed for pickle)\n",
    "word2vec_embeddings = df['word2vec_embedding'].tolist()\n",
    "\n",
    "# Save Word2Vec embeddings\n",
    "word2vec_path = '/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/word2vec_vectorized.pkl'\n",
    "with open(word2vec_path, 'wb') as f:\n",
    "    pickle.dump(word2vec_embeddings, f)\n",
    "\n",
    "print(f\"Word2Vec embeddings successfully saved to {word2vec_path}\")\n",
    "\n",
    "df[['word2vec_embedding']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings successfully saved to bert_vectorized.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.059372894, 0.87842745, 0.42169085, 0.00433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.22069171, 0.65713084, 0.33688197, -0.20024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.28149357, 0.7224497, 0.23585524, -0.108056...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.10413745, 0.7803177, 0.3849645, -0.0113108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.17919672, 0.6800731, 0.50333893, -0.045008...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bert_embedding\n",
       "0  [-0.059372894, 0.87842745, 0.42169085, 0.00433...\n",
       "1  [-0.22069171, 0.65713084, 0.33688197, -0.20024...\n",
       "2  [-0.28149357, 0.7224497, 0.23585524, -0.108056...\n",
       "3  [-0.10413745, 0.7803177, 0.3849645, -0.0113108...\n",
       "4  [-0.17919672, 0.6800731, 0.50333893, -0.045008..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**tokens)\n",
    "    return output.last_hidden_state[:,0,:].cpu().numpy().flatten()\n",
    "\n",
    "df['bert_embedding'] = df['lemmatized_text'].apply(get_bert_embeddings)\n",
    "\n",
    "with open('/home/azureuser/cloudfiles/code/Users/oskar.wolf/nlp_air_france_reviews/data/interim/bert_vectorized.pkl', 'wb') as f:\n",
    "    pickle.dump(df['bert_embedding'].tolist(), f)\n",
    "    \n",
    "print(\"BERT embeddings successfully saved to bert_vectorized.pkl\")\n",
    "\n",
    "df[['bert_embedding']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_airfrance_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
